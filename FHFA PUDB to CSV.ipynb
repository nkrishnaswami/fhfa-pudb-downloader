{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The FHFA PUDB files are as space-padded, fixed-width columns, and the coding/data dictionary is in PDF files.\n",
    "\n",
    "I downloaded the PUDB archives and data dictionaries using [downloader.ipynb](downloader.ipynb), extracted the (somewhat noisy) tables using `tabula`, and use them to automate CSV generation from the PUDB txt files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import struct\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_codes(val):\n",
    "    for code in re.findall('[0-9.]+ = .*?(?=[0-9.]+ = |$)', val):\n",
    "        fld = re.split(' = ', code)\n",
    "        if len(fld) == 2 and re.match(r'^[\\d.]+$', fld[0]):\n",
    "            yield((fld[0].strip(), fld[1].strip()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_recs(row):\n",
    "    fld_nums = re.match('(\\d+)-(\\d+)$', row['Field #'])\n",
    "    fld_names = re.match('(.*) (\\d+)-(\\d+)$', row['Field Name'])\n",
    "    if fld_nums and fld_names:\n",
    "        num_lo = int(fld_nums.group(1))\n",
    "        num_hi = int(fld_nums.group(2))\n",
    "        name_pfx = fld_names.group(1)\n",
    "        name_lo = int(fld_names.group(2))\n",
    "        name_hi = int(fld_names.group(3))\n",
    "        for num_idx, name_idx in zip(\n",
    "            range(num_lo, num_hi + 1),\n",
    "            range(name_lo, name_hi + 1)):\n",
    "            ret = row.copy()\n",
    "            ret['Field Name'] = name_pfx + \" \" + str(name_idx)\n",
    "            ret['Field #'] = num_idx\n",
    "            yield ret\n",
    "    else:\n",
    "        ret = row.copy()\n",
    "        ret['Field #'] = int(ret['Field #'])\n",
    "        yield ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mf_metadata(filename):\n",
    "    mf_metadata = pd.read_csv(filename, encoding='iso8859-1')\n",
    "    mf_metadata['Values'] = mf_metadata['Values'].fillna('').apply(lambda val: dict(split_codes(val)))\n",
    "    mf_metadata = mf_metadata[\n",
    "        mf_metadata['Field #'].str.match(r'[\\d-]+$') &\n",
    "        ~pd.isnull(mf_metadata['Field #'])\n",
    "    ]\n",
    "    mf_metadata['Field #'] = mf_metadata['Field #'].astype(int)\n",
    "    mf_metadata = mf_metadata.set_index('Field #').sort_index()\n",
    "    return mf_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sf_metadata(filename):\n",
    "    sf_metadata = pd.read_csv(filename, encoding='iso8859-1')\n",
    "    sf_metadata['Values'] = sf_metadata['Values'].fillna('').apply(lambda val: dict(split_codes(val)))\n",
    "    out = []\n",
    "    sf_metadata = sf_metadata[\n",
    "        sf_metadata['Field #'].str.match(r'[\\d-]+$') &\n",
    "        ~pd.isnull(sf_metadata['Field #'])\n",
    "    ]\n",
    "    sf_metadata.apply(\n",
    "        lambda row: out.extend(list(split_recs(row))),\n",
    "        axis=1)\n",
    "    sf_metadata = pd.DataFrame(out).reset_index(drop=True)\n",
    "    sf_metadata['Field #'] = sf_metadata['Field #'].astype(int)\n",
    "    sf_metadata = sf_metadata.set_index('Field #').sort_index()\n",
    "    return sf_metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we can load the data using the transformed metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhfa_reader(path, metadata, decode, zip=None):\n",
    "    line_fmt = ''\n",
    "    for field in metadata.index:\n",
    "        line_fmt += 'x{}s'.format(metadata.loc[field, 'Field Width'])\n",
    "    line_fmt = line_fmt[1:]\n",
    "    with (zip and zipfile.ZipFile(zip).open(path)) or open(path, 'rb') as f:\n",
    "        for lineno, line in enumerate(f, 1):\n",
    "            try:\n",
    "                match = tuple(x.strip().decode('utf-8') for x in struct.unpack(line_fmt, line.strip()))\n",
    "            except struct.error as e:\n",
    "                raise ValueError(str(e) + \" line length is {}\".format(len(line.strip())))\n",
    "                \n",
    "            if not match:\n",
    "                print(\"Failed to match line \", lineno)\n",
    "            else:\n",
    "                if decode:\n",
    "                    yield tuple(metadata.loc[idx, 'Values'].get(i, i) for idx,i in enumerate(match, 1))\n",
    "                else:\n",
    "                    yield match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fhfa_to_csv(basename, metadata, decode=False, zip=None):\n",
    "    with open(basename+'.csv', 'w') as out:\n",
    "        cout = csv.writer(out)\n",
    "        cout.writerow(tuple(metadata['Field Name'].values))\n",
    "        cout.writerows(fhfa_reader(basename + '.txt', metadata, decode, zip))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_year(year):\n",
    "    print(\"Processing data for\", year)\n",
    "    mf_metadata = get_mf_metadata('{}_Multifamily_Census_Tract_File.csv'.format(year))\n",
    "    sf_metadata = get_sf_metadata('{}_Single_Family_Census_Tract_File.csv'.format(year))\n",
    "    print(\"  Freddie Mac multifamily\")\n",
    "    fhfa_to_csv('fhlmc_mf{}c_loans'.format(year), mf_metadata, zip='{}_MFCensusTract{}.zip'.format(year, year))\n",
    "    print(\"  Fannie Mae multifamily\")\n",
    "    fhfa_to_csv('fnma_mf{}c_loans'.format(year), mf_metadata, zip='{}_MFCensusTract{}.zip'.format(year, year))\n",
    "    print(\"  Freddie Mac single family\")\n",
    "    fhfa_to_csv('fhlmc_sf{}c_loans'.format(year), sf_metadata, zip='{}_SFCensusTractFRE{}.zip'.format(year, year))\n",
    "    print(\"  Fannie Mae single family\")\n",
    "    fhfa_to_csv('fnma_sf{}c_loans'.format(year), sf_metadata, zip='{}_SFCensusTractFNM{}.zip'.format(year, year))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for year in range(2008, 2017):\n",
    "    %time do_year(year)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
